hydra:
    run:
        dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    job:
        chdir: True

defaults:
  - logging: clearml
  - loss: L2

project:
  name: Dataset Alignment
  task: Pretrain-MultiScaleConvolution

finetune:
  restore_file: null

common:
  seed: 1234
  auto_batch_size: false
  lr: 0.0001

data:
  _target_: alignnet.AudioDataModule
  data_dirs: ???
  batch_size: 16
  num_workers: 6
  persistent_workers: true
  transform_time: get
  cache: false
  time_dim: 1
  fs: 16000
  pathcol: audio_path

dataclass:
  _target_: hydra.utils.get_class
  path: alignnet.AudioData

optimization:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  devices:
  - 1
  log_every_n_steps: 5
  max_epochs: 200
  precision: 16-mixed

earlystop:
  _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
  patience: 20

model:
  _target_: alignnet.Model

network:
  _target_: alignnet.AlignNet
  aligner_corr_threshold: null
  audio_net:
    _target_: alignnet.MultiScaleConvolution
    path1:
      _target_: alignnet.ConvPath
      kernels:
      - 3
      - 3
      - 3
      - 3
      - 3
      strides:
      - 1
      dilations:
      - 1
      channels:
      - 32
      paddings:
      - 1
      pooling_kernels:
      - 4
      - 4
      - 5
      - 5
      - 5
    path2:
      _target_: alignnet.ConvPath
      kernels:
      - 11
      - 11
      - 11
      - 11
      - 11
      strides:
      - 4
      dilations:
      - 1
      paddings:
      - 5
      channels:
      - 32
      pooling_type: null
    path3:
      _target_: alignnet.ConvPath
      rectify: True
      kernels:
      - 11
      - 11
      - 11
      - 11
      - 11
      strides:
      - 4
      dilations:
      - 1
      paddings:
      - 5
      channels:
      - 32
      pooling_type: null
    path4:
      _target_: alignnet.ConvPath
      mu_law: True
      kernels:
      - 3
      - 3
      - 3
      - 3
      - 3
      strides:
      - 1
      dilations:
      - 1
      channels:
      - 32
      paddings:
      - 1
      pooling_kernels:
      - 4
      - 4
      - 5
      - 5
      - 5
  aligner:
    _target_: alignnet.NoAligner

checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: val_loss
  mode: min
  filename: '{epoch}-{val_loss:.4f}'
  save_top_k: 5
  every_n_epochs: 1
  every_n_train_steps: null

optimizer:
  _target_: alignnet.OptimizerWrapper
  class_name: torch.optim.Adam

transform:
  _target_: alignnet.NoneTransform